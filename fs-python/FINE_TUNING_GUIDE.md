# Fish Speech Fine-tuning Guide

–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ fine-tuning –º–æ–¥–µ–ª–∏ Fish Speech –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤.

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–û–±–∑–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–∞](#–æ–±–∑–æ—Ä-–ø—Ä–æ—Ü–µ—Å—Å–∞)
2. [–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è](#—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
3. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö](#–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–¥–∞–Ω–Ω—ã—Ö)
4. [Fine-tuning –º–æ–¥–µ–ª–∏](#fine-tuning-–º–æ–¥–µ–ª–∏)
5. [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏](#–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ-–º–æ–¥–µ–ª–∏)
6. [–ü—Ä–∏–º–µ—Ä—ã](#–ø—Ä–∏–º–µ—Ä—ã)
7. [Troubleshooting](#troubleshooting)

## –û–±–∑–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–∞

Fine-tuning Fish Speech —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤:

1. **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö** - –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
2. **–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤** - –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ç–æ–∫–µ–Ω—ã
3. **–°–æ–∑–¥–∞–Ω–∏–µ protobuf –¥–∞—Ç–∞—Å–µ—Ç–∞** - —É–ø–∞–∫–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
4. **Fine-tuning —Å LoRA** - –∞–¥–∞–ø—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø–æ–¥ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ
5. **–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤** - —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Python 3.10+**
- **GPU**: –º–∏–Ω–∏–º—É–º 8GB VRAM (–¥–ª—è fine-tuning), 4GB (–¥–ª—è inference)
- **RAM**: –º–∏–Ω–∏–º—É–º 16GB
- **–ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ**: 10-20GB (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞)
- **–í—Ä–µ–º—è**: 1-4 —á–∞—Å–∞ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ GPU)

### –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
poetry run pip install librosa soundfile whisper tqdm yt-dlp

# –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ —Å YouTube (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
pip install yt-dlp
```

### –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö

- **–ú–∏–Ω–∏–º—É–º**: 10-30 –º–∏–Ω—É—Ç –∞—É–¥–∏–æ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è**: 30-60 –º–∏–Ω—É—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
- **–§–æ—Ä–º–∞—Ç**: 44.1kHz, mono, WAV/MP3/FLAC
- **–ß–∏—Å—Ç–æ—Ç–∞**: –º–∏–Ω–∏–º—É–º —Ñ–æ–Ω–æ–≤–æ–≥–æ —à—É–º–∞, —á–µ—Ç–∫–∞—è —Ä–µ—á—å
- **–¢–µ–∫—Å—Ç**: —Ç–æ—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞

## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞

```bash
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ —Å –∞—É–¥–∏–æ
poetry run python prepare_dataset.py \
  --input /path/to/raw/audio \
  --output training_data/my_voice \
  --normalize \
  --split-long \
  --auto-transcribe

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å YouTube (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ 10—Å)
poetry run python prepare_dataset.py \
  --input "https://youtube.com/watch?v=VIDEO_ID" \
  --output training_data/youtube_voice \
  --speaker "YouTuber_Name" \
  --youtube \
  --auto-transcribe \
  --whisper-model medium \
  --segment-duration 10

# –ö–∞—Å—Ç–æ–º–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 15 —Å–µ–∫—É–Ω–¥)
poetry run python prepare_dataset.py \
  --input "https://youtube.com/watch?v=VIDEO_ID" \
  --output training_data/youtube_voice \
  --speaker "YouTuber_Name" \
  --youtube \
  --auto-transcribe \
  --whisper-model medium \
  --segment-duration 15

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã—Ö 20 –º–∏–Ω—É—Ç –≤–∏–¥–µ–æ
poetry run python prepare_dataset.py \
  --input "https://youtube.com/watch?v=VIDEO_ID" \
  --output training_data/youtube_voice \
  --speaker "YouTuber_Name" \
  --youtube \
  --auto-transcribe \
  --whisper-model medium \
  --max-duration 20

# –ö–æ–º–±–∏–Ω–∞—Ü–∏—è: –ø–µ—Ä–≤—ã–µ 30 –º–∏–Ω—É—Ç + —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ 12 —Å–µ–∫—É–Ω–¥
poetry run python prepare_dataset.py \
  --input "https://youtube.com/watch?v=VIDEO_ID" \
  --output training_data/youtube_voice \
  --speaker "YouTuber_Name" \
  --youtube \
  --auto-transcribe \
  --whisper-model medium \
  --segment-duration 12 \
  --max-duration 30
```

### –†—É—á–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞

–ï—Å–ª–∏ —É –≤–∞—Å —É–∂–µ –µ—Å—Ç—å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –æ—Ä–≥–∞–Ω–∏–∑—É–π—Ç–µ –∏—Ö —Ç–∞–∫:

```
training_data/
‚îî‚îÄ‚îÄ my_voice/
    ‚îú‚îÄ‚îÄ SPEAKER_NAME/
    ‚îÇ   ‚îú‚îÄ‚îÄ audio_001.wav
    ‚îÇ   ‚îú‚îÄ‚îÄ audio_001.lab
    ‚îÇ   ‚îú‚îÄ‚îÄ audio_002.wav
    ‚îÇ   ‚îú‚îÄ‚îÄ audio_002.lab
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ dataset_summary.json
```

–ì–¥–µ:
- `.wav` —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—ã (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ 10-30 —Å–µ–∫—É–Ω–¥)
- `.lab` —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ—á–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ
- –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å (–∫—Ä–æ–º–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)

## Fine-tuning –º–æ–¥–µ–ª–∏

### –ü–æ–ª–Ω—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞–π–ø–ª–∞–π–Ω

```bash
# –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
poetry run python finetune_tts.py \
  --project my_custom_voice \
  --data-dir training_data/my_voice \
  --model-version 1.5 \
  --full-pipeline \
  --max-steps 1000 \
  --batch-size 4 \
  --learning-rate 1e-4
```

### –ü–æ—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å

```bash
# –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –Ω–µ —Å–¥–µ–ª–∞–Ω–æ)
poetry run python finetune_tts.py \
  --project my_custom_voice \
  --data-dir raw_audio/ \
  --prepare-data

# –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤
poetry run python finetune_tts.py \
  --project my_custom_voice \
  --data-dir training_data/my_custom_voice \
  --extract-tokens \
  --batch-size-extract 16

# –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
poetry run python finetune_tts.py \
  --project my_custom_voice \
  --data-dir training_data/my_custom_voice \
  --train \
  --max-steps 200 \
  --batch-size 2 \
  --learning-rate 5e-5

# –®–∞–≥ 4: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤
poetry run python finetune_tts.py \
  --project my_custom_voice \
  --merge-weights \
  --data-dir training_data/my_custom_voice
```

### –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è

‚ö†Ô∏è **–í–∞–∂–Ω–æ**: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é –∏–ª–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏!

| –ü–∞—Ä–∞–º–µ—Ç—Ä | "–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ" –∑–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|----------|----------------------|-------------|
| **VRAM** | ‚â• 8 –ì–ë –¥–ª—è fine-tune | –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ |
| **batch_size** | 2-4 (–ø—Ä–∏ 8 –ì–ë) | –° —É—á—ë—Ç–æ–º gradient_accumulation_steps –ª–µ–≥–∫–æ —É–≤–µ–ª–∏—á–∏—Ç—å ¬´–ª–æ–≥–∏—á–µ—Å–∫–∏–π¬ª batch |
| **learning_rate** | 1e-5 ‚Äì 5e-5 | –ë–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π LR –¥–∞—ë—Ç —à—É–º / ¬´–ø—Ä–æ–≤–∞–ª¬ª –ø–æ—Å–ª–µ 300 —à–∞–≥–æ–≤ |
| **max_steps** | 100-300 | –•–≤–∞—Ç–∞–µ—Ç, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å ¬´–ø–æ–¥—Ö–≤–∞—Ç–∏–ª–∞¬ª –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é; –¥–∞–ª—å—à–µ ‚Äî —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è |
| **LoRA rank / Œ±** | r_8_alpha_16 | –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ –≥–∞–π–¥–µ |

### ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è Fine-tuning

**–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é fine-tune –æ–±—É—á–∞–µ—Ç –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏–µ, –Ω–æ –Ω–µ —Ç–µ–º–±—Ä.**

- **–î–ª—è —Ç–µ–º–±—Ä–∞ –Ω—É–∂–Ω–æ**: –±–æ–ª—å—à–µ —à–∞–≥–æ–≤ (‚âà 500-1000) + —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
- **–†–∏—Å–∫**: –±–µ–∑ —ç—Ç–æ–≥–æ –≥–æ–ª–æ—Å ¬´–ø–æ–ø–ª—ã–≤—ë—Ç¬ª - –º–æ–∂–µ—Ç —Å—Ç–∞—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º –∏–ª–∏ –Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å 100-300 —à–∞–≥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞, –∑–∞—Ç–µ–º —É–≤–µ–ª–∏—á–∏–≤–∞–π—Ç–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

**–ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è:**
- –ì–æ–ª–æ—Å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ä–æ–±–æ—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
- –ü–æ—è–≤–ª—è—é—Ç—Å—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏ —à—É–º—ã
- –ú–æ–¥–µ–ª—å —Ç–µ—Ä—è–µ—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ—á–∏
- Loss –ø–µ—Ä–µ—Å—Ç–∞—ë—Ç —Å–Ω–∏–∂–∞—Ç—å—Å—è –∏–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç —Ä–∞—Å—Ç–∏

### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ü–µ–ª–µ–π

#### üéØ –î–ª—è –∏–∑—É—á–µ–Ω–∏—è –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—è (–±—ã—Å—Ç—Ä–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
```bash
poetry run python finetune_tts.py \
  --project quick_pronunciation \
  --data-dir training_data/my_voice \
  --train \
  --max-steps 100 \
  --batch-size 2 \
  --learning-rate 2e-5
```
**–†–µ–∑—É–ª—å—Ç–∞—Ç**: –ú–æ–¥–µ–ª—å –Ω–∞—É—á–∏—Ç—Å—è –±–∞–∑–æ–≤–æ–º—É –ø—Ä–æ–∏–∑–Ω–æ—à–µ–Ω–∏—é –∑–∞ 15-30 –º–∏–Ω—É—Ç

#### üé§ –î–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —Ç–µ–º–±—Ä–∞ –≥–æ–ª–æ—Å–∞ (–º–µ–¥–ª–µ–Ω–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏)
```bash
# –ü–µ—Ä–≤—ã–π —ç—Ç–∞–ø: –±–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
poetry run python finetune_tts.py \
  --project voice_timbre_stage1 \
  --data-dir training_data/my_voice \
  --train \
  --max-steps 300 \
  --batch-size 2 \
  --learning-rate 2e-5

# –í—Ç–æ—Ä–æ–π —ç—Ç–∞–ø: —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ–º–±—Ä–∞
poetry run python finetune_tts.py \
  --project voice_timbre_stage2 \
  --data-dir training_data/my_voice \
  --train \
  --max-steps 500 \
  --batch-size 1 \
  --learning-rate 1e-5 \
  --checkpoint-path results/voice_timbre_stage1/checkpoints/
```
**–†–µ–∑—É–ª—å—Ç–∞—Ç**: –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Ç–µ–º–±—Ä–∞, –Ω–æ —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

### –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è fine-tuning

–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤:
```
checkpoints/my_custom_voice-merged/
‚îú‚îÄ‚îÄ model.pth              # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å (~1.2GB)
‚îú‚îÄ‚îÄ tokenizer.tiktoken     # –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (~1.6MB)
‚îú‚îÄ‚îÄ config.json            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
‚îî‚îÄ‚îÄ special_tokens.json    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å CLI TTS

–û–±–Ω–æ–≤–∏—Ç–µ `cli_tts.py` —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∞—à—É –º–æ–¥–µ–ª—å:

```python
# –í —Ñ—É–Ω–∫—Ü–∏–∏ setup_fish_speech() –¥–æ–±–∞–≤—å—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
custom_model_path = "checkpoints/my_custom_voice-merged"
if Path(custom_model_path).exists():
    print(f"üé§ –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {custom_model_path}")
    return fish_speech_dir, Path(custom_model_path)
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ**, —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –Ω–∞–ø—Ä—è–º—É—é –ø—Ä–∏ –≤—ã–∑–æ–≤–µ TTS:

```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
poetry run python cli_tts.py "–¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞—à—É –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å" \
  --model-path checkpoints/test_limited-merged \
  -o output/test_finetuned.wav \
  --play
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

```bash
# –¢–µ—Å—Ç —Å –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª—å—é
poetry run python cli_tts.py "–¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞—à—É –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å" \
  --model-path checkpoints/my_custom_voice-merged \
  -o output/test_finetuned.wav \
  --play
```

## –ü—Ä–∏–º–µ—Ä—ã

### –ü—Ä–∏–º–µ—Ä 1: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∑–∞–ø–∏—Å—è—Ö –ø–æ–¥–∫–∞—Å—Ç–∞

```bash
# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–¥–∫–∞—Å—Ç —Å YouTube
poetry run python prepare_dataset.py \
  --input "https://youtube.com/watch?v=PODCAST_ID" \
  --output training_data/podcast_host \
  --speaker "PodcastHost" \
  --youtube \
  --auto-transcribe \
  --whisper-model large \
  --split-long

# 2. –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
poetry run python finetune_tts.py \
  --project podcast_voice \
  --data-dir training_data/podcast_host \
  --full-pipeline \
  --max-steps 1500 \
  --batch-size 4
```

### –ü—Ä–∏–º–µ—Ä 2: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∞—É–¥–∏–æ–∫–Ω–∏–≥–µ

```bash
# 1. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–∞–≤—ã –∞—É–¥–∏–æ–∫–Ω–∏–≥–∏
poetry run python prepare_dataset.py \
  --input audiobook_chapters/ \
  --output training_data/narrator \
  --normalize \
  --split-long \
  --auto-transcribe \
  --whisper-model base

# 2. –û–±—É—á–µ–Ω–∏–µ —Å –º–µ–Ω—å—à–∏–º learning rate (–¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞)
poetry run python finetune_tts.py \
  --project audiobook_narrator \
  --data-dir training_data/narrator \
  --full-pipeline \
  --max-steps 200 \
  --batch-size 2 \
  --learning-rate 2e-5
```

### –ü—Ä–∏–º–µ—Ä 3: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º –≥–æ–ª–æ—Å–µ

```bash
# 1. –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–≤–æ–π –≥–æ–ª–æ—Å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 30-45 –º–∏–Ω—É—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫: my_voice/recordings/session_01.wav, session_02.wav, etc.
# –°–æ–∑–¥–∞—ë–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã: session_01.txt, session_02.txt

# 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
poetry run python prepare_dataset.py \
  --input my_voice/recordings \
  --output training_data/my_voice \
  --speaker "MyVoice" \
  --normalize \
  --split-long

# 3. –û–±—É—á–µ–Ω–∏–µ —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
poetry run python finetune_tts.py \
  --project my_personal_voice \
  --data-dir training_data/my_voice \
  --full-pipeline \
  --max-steps 1000 \
  --batch-size 4 \
  --learning-rate 1e-4 \
  --device mps  # –¥–ª—è Apple Silicon
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è

–õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:
```
fish-speech/results/my_custom_voice/
‚îú‚îÄ‚îÄ checkpoints/
‚îú‚îÄ‚îÄ logs/
‚îî‚îÄ‚îÄ training_configs/
```

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

–°–ª–µ–¥–∏—Ç–µ –∑–∞:
- **Loss**: –¥–æ–ª–∂–µ–Ω –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞—Ç—å—Å—è
- **Learning Rate**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è
- **GPU Memory**: –Ω–µ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–≤—ã—à–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—É—é

### –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è

–û–±—É—á–µ–Ω–∏–µ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç –Ω–∞–∂–∞—Ç–∏–µ–º `Ctrl+C`. –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤.

## Troubleshooting

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

**1. Out of Memory (OOM)**
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ batch size
--batch-size 1

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ gradient accumulation
--gradient-accumulation-steps 4
```

**2. –ú–æ–¥–µ–ª—å –Ω–µ —Å—Ö–æ–¥–∏—Ç—Å—è**
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ learning rate
--learning-rate 5e-5

# –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
--max-steps 2000
```

**3. –ù–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
poetry run python prepare_dataset.py --input training_data/ --output check_data/ --auto-transcribe

# –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π checkpoint
--checkpoint-step 500  # –≤–º–µ—Å—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
```

**4. –î–æ–ª–≥–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à–∏–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
--max-steps 500

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
nvidia-smi  # –¥–ª—è NVIDIA
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

```bash
# –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
poetry run python -c "
import json
with open('training_data/my_voice/dataset_summary.json') as f:
    summary = json.load(f)
    print(f'–§–∞–π–ª–æ–≤: {summary["total_files"]}')
    print(f'–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {summary["total_duration_minutes"]} –º–∏–Ω')
    print(f'–°–ø–∏–∫–µ—Ä—ã: {summary["speakers"]}')
"
```

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–î–ª—è Apple Silicon (MPS):**
```bash
--device mps
--batch-size 2  # MPS –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º —Å –±–æ–ª—å—à–∏–º–∏ –±–∞—Ç—á–∞–º–∏
```

**–î–ª—è NVIDIA GPU:**
```bash
--device cuda
--batch-size 4  # –∏–ª–∏ –±–æ–ª—å—à–µ –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å
```

**–î–ª—è CPU (–º–µ–¥–ª–µ–Ω–Ω–æ):**
```bash
--device cpu
--batch-size 1
--max-steps 100  # –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
```

## –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º–∞: –û—à–∏–±–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ LoRA —Å–ª–æ—è—Ö

**–°–∏–º–ø—Ç–æ–º—ã:**
```
RuntimeError: expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float
```

**–ü—Ä–∏—á–∏–Ω–∞:** 
–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Fish Speech –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Å BFloat16 —Ç–æ—á–Ω–æ—Å—Ç—å—é, –∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –≤ Float32. –≠—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –º–∞—Ç—Ä–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö.

**–†–µ—à–µ–Ω–∏—è:**

1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):** –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç FP32 –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
   ```bash
   # –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–æ–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å
   poetry run python finetune_tts.py --project my_voice --data-dir training_data/my_voice --train
   ```

2. **–ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è:** –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏—Ç–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å
   ```bash
   # –Ø–≤–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
   poetry run python finetune_tts.py --project my_voice --data-dir training_data/my_voice --train --device cpu --batch-size 1
   ```

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:**
- –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å Fish Speech —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å BFloat16 —Ç–æ—á–Ω–æ—Å—Ç—å—é
- LoRA —Å–ª–æ–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ–∑–¥–∞—é—Ç—Å—è –≤ Float32
- –°–∫—Ä–∏–ø—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç FP32 –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (`trainer.precision=32` + `model.torch_dtype=float32`)
- –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –Ω–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å

### –ü—Ä–æ–±–ª–µ–º–∞: –û—à–∏–±–∫–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –Ω–∞ Apple Silicon (MPS)

**–°–∏–º–ø—Ç–æ–º—ã:**
```
RuntimeError: Expected scalar_type == ScalarType::Float || inputTensor.scalar_type() == ScalarType::Int || scalar_type == ScalarType::Bool to be true, but got false.
```

**–ü—Ä–∏—á–∏–Ω–∞:** 
MPS (Metal Performance Shaders) –Ω–∞ Apple Silicon –∏–º–µ–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ PyTorch, –æ—Å–æ–±–µ–Ω–Ω–æ —Å mixed precision training –∏ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤.

**–†–µ—à–µ–Ω–∏—è:**

1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):** –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ CPU –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ Apple Silicon
   ```bash
   # CPU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ Apple Silicon
   poetry run python finetune_tts.py --project my_voice --data-dir training_data/my_voice --train
   ```

2. **–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ MPS (—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ):**
   ```bash
   # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å MPS —Å –ø–æ–ª–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
   poetry run python finetune_tts.py --project my_voice --data-dir training_data/my_voice --train --force-mps
   ```

3. **–Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ CPU:**
   ```bash
   # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU
   poetry run python finetune_tts.py --project my_voice --data-dir training_data/my_voice --train --device cpu
   ```

**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ Apple Silicon:**
- **CPU:** –°—Ç–∞–±–∏–ª—å–Ω–æ, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –º–µ–¥–ª–µ–Ω–Ω–µ–µ GPU
- **MPS:** –ë—ã—Å—Ç—Ä–µ–µ CPU, –Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º —Å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—á–∞—Ç—å —Å CPU, –∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å `--force-mps`

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

**–°–∏–º–ø—Ç–æ–º—ã:** –û–±—É—á–µ–Ω–∏–µ –∏–¥—ë—Ç –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ

**–†–µ—à–µ–Ω–∏—è:**
1. –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: `--batch-size 1`
2. –£–º–µ–Ω—å—à–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: `--max-steps 500`
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à–∏–π LoRA rank: `--lora-config r_4_alpha_8`
4. –ï—Å–ª–∏ –µ—Å—Ç—å NVIDIA GPU, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `--device cuda`

### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏

**–°–∏–º–ø—Ç–æ–º—ã:** 
```
RuntimeError: [enforce fail at alloc_cpu.cpp] data.
OutOfMemoryError: Unable to allocate array
```

**–†–µ—à–µ–Ω–∏—è:**
1. –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–æ 1: `--batch-size 1`
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CPU –≤–º–µ—Å—Ç–æ GPU: `--device cpu`
3. –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
4. –£–º–µ–Ω—å—à–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ worker'–æ–≤: `--num-workers-extract 1`

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏

### –°–º–µ—à–∏–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤

–ú–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–æ–ª–æ—Å–∞—Ö:

```bash
# –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
poetry run python prepare_dataset.py --input speaker1_data/ --output training_data/multi_voice --speaker Speaker1
poetry run python prepare_dataset.py --input speaker2_data/ --output training_data/multi_voice --speaker Speaker2

# –û–±—É—á–∞–µ–º –Ω–∞ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
poetry run python finetune_tts.py \
  --project multi_voice_model \
  --data-dir training_data/multi_voice \
  --full-pipeline
```

### –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```bash
# –î–æ–æ–±—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏
poetry run python finetune_tts.py \
  --project my_voice_v2 \
  --data-dir new_training_data/ \
  --train \
  --pretrained-ckpt-path checkpoints/my_custom_voice-merged/
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏
ls -lh checkpoints/my_custom_voice-merged/

# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ:
# model.pth              ~1.2GB   # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
# tokenizer.tiktoken     ~1.6MB   # –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
# config.json            ~1KB     # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# special_tokens.json    ~30KB    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
```

**–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã:**
- `model.pth`: 1.0-1.3 GB (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏)
- `tokenizer.tiktoken`: 1-2 MB (—Å–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤)
- `config.json`: –º–µ–Ω–µ–µ 1 KB (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏)
- `special_tokens.json`: 20-40 KB (—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã)

–ï—Å–ª–∏ –∫–∞–∫–æ–π-—Ç–æ —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è.

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å LoRA

```bash
# –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
--lora-config r_16_alpha_32

# –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ  
--lora-config r_4_alpha_8
```

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

Fine-tuning Fish Speech –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –≥–æ–ª–æ—Å–∞. –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞:

1. **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**: —á–∏—Å—Ç—ã–µ –∑–∞–ø–∏—Å–∏ —Å —Ç–æ—á–Ω–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π
2. **–î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä—ë–º**: –º–∏–Ω–∏–º—É–º 10-30 –º–∏–Ω—É—Ç –∞—É–¥–∏–æ
3. **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã**: –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
4. **–¢–µ—Ä–ø–µ–Ω–∏–µ**: —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–µ–±—É—é—Ç –≤—Ä–µ–º–µ–Ω–∏

–£—Å–ø–µ—à–Ω–æ–≥–æ fine-tuning! üé§‚ú®